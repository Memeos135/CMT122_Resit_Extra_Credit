{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Gb5YzPVq_RTZ",
        "7wKaV0wa_YsE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 - Question 2\n",
        "Please make sure to upload the dataset \"SemEval2017 Task4_Sentiment_Analysis.csv\" before running the code."
      ],
      "metadata": {
        "id": "Gb5YzPVq_RTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGGDZp5KyQl9",
        "outputId": "6084f56a-d8af-4952-85b2-0680d603539e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Accuracy: 0.668\n",
            "Regression RMSE: 0.558\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"SemEval2017 Task4_ Sentiment_Analysis.csv\")\n",
        "\n",
        "# Encode for classification\n",
        "le = LabelEncoder()\n",
        "df[\"label_encoded\"] = le.fit_transform(df[\"label\"])\n",
        "\n",
        "# Map for regression\n",
        "sentiment_mapping = {\"positive\": 1, \"neutral\": 0, \"negative\": -1}\n",
        "df[\"label_regression\"] = df[\"label\"].map(sentiment_mapping)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train_cls, y_test_cls = train_test_split(df[\"text\"], df[\"label_encoded\"], test_size=0.2, random_state=42)\n",
        "_, _, y_train_reg, y_test_reg = train_test_split(df[\"text\"], df[\"label_regression\"], test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Classification model\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "y_pred_cls = clf.fit(X_train_tfidf, y_train_cls).predict(X_test_tfidf)\n",
        "accuracy = accuracy_score(y_test_cls, y_pred_cls)\n",
        "\n",
        "# Regression model\n",
        "reg = Ridge()\n",
        "y_pred_reg = reg.fit(X_train_tfidf, y_train_reg).predict(X_test_tfidf)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))\n",
        "\n",
        "# Output results\n",
        "print(f\"Classification Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Regression RMSE: {rmse:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2\n",
        "Please make sure to upload the dataset \"20_Newsgroups.csv\" before running the code"
      ],
      "metadata": {
        "id": "7wKaV0wa_YsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# === Load and Clean Data ===\n",
        "df = pd.read_csv(\"20_Newsgroups.csv\")\n",
        "\n",
        "# Remove empty rows\n",
        "df = df.dropna(subset=[\"text\", \"label\"])\n",
        "df = df[df[\"text\"].str.strip() != \"\"]\n",
        "df = df[df[\"label\"].str.strip() != \"\"]\n",
        "\n",
        "# Keep only labels: class-0 to class-5\n",
        "valid_labels = {f'class-{i}' for i in range(6)}\n",
        "df = df[df[\"label\"].isin(valid_labels)].copy()\n",
        "\n",
        "# Clean text: lowercase, remove emails, URLs, digits, symbols\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Encode labels to integers\n",
        "le = LabelEncoder()\n",
        "df['label_enc'] = le.fit_transform(df['label'])\n",
        "\n",
        "# === Prepare Text and Labels ===\n",
        "X_text = df['clean_text']\n",
        "y = df['label_enc']\n",
        "\n",
        "# Split: train/dev/test = 60/20/20\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X_text, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)\n",
        "\n",
        "# === Feature 1: TF-IDF ===\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_dev_tfidf = tfidf.transform(X_dev)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# === Feature 2â€“5: Custom Numerical Features ===\n",
        "def avg_word_length(texts):\n",
        "    return np.array([[np.mean([len(w) for w in t.split()]) if t.split() else 0] for t in texts])\n",
        "\n",
        "def digit_count(texts):\n",
        "    return np.array([[sum(c.isdigit() for c in t)] for t in texts])\n",
        "\n",
        "def unique_word_count(texts):\n",
        "    return np.array([[len(set(t.split()))] for t in texts])\n",
        "\n",
        "def capital_letter_count(texts):\n",
        "    return np.array([[sum(c.isupper() for c in t)] for t in texts])\n",
        "\n",
        "# Compute features\n",
        "avg_train = avg_word_length(X_train)\n",
        "avg_dev = avg_word_length(X_dev)\n",
        "avg_test = avg_word_length(X_test)\n",
        "\n",
        "digit_train = digit_count(X_train)\n",
        "digit_dev = digit_count(X_dev)\n",
        "digit_test = digit_count(X_test)\n",
        "\n",
        "uniq_train = unique_word_count(X_train)\n",
        "uniq_dev = unique_word_count(X_dev)\n",
        "uniq_test = unique_word_count(X_test)\n",
        "\n",
        "caps_train = capital_letter_count(X_train)\n",
        "caps_dev = capital_letter_count(X_dev)\n",
        "caps_test = capital_letter_count(X_test)\n",
        "\n",
        "# === Combine All Features ===\n",
        "X_train_combined = hstack([X_train_tfidf, avg_train, digit_train, uniq_train, caps_train])\n",
        "X_dev_combined = hstack([X_dev_tfidf, avg_dev, digit_dev, uniq_dev, caps_dev])\n",
        "X_test_combined = hstack([X_test_tfidf, avg_test, digit_test, uniq_test, caps_test])\n",
        "\n",
        "# === Train and Evaluate Model ===\n",
        "clf = LogisticRegression(max_iter=3000)\n",
        "clf.fit(X_train_combined, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test_combined)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "\n",
        "# === Output Results ===\n",
        "print(f\"Accuracy: {acc:.3f}\")\n",
        "print(f\"Macro Precision: {prec:.3f}\")\n",
        "print(f\"Macro Recall: {rec:.3f}\")\n",
        "print(f\"Macro F1: {f1:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObKPaBRC7F5a",
        "outputId": "528947dc-6fb1-4eaa-e102-739d0a5b5ca2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.848\n",
            "Macro Precision: 0.856\n",
            "Macro Recall: 0.852\n",
            "Macro F1: 0.853\n"
          ]
        }
      ]
    }
  ]
}